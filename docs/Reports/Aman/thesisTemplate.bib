@inproceedings{ahir,
author = {Sahasrabuddhe, Sameer and Raja, Hakim and Arya, Kavi and Desai, Madhav},
year = {2007},
month = {01},
pages = {245-250},
title = {AHIR: A Hardware Intermediate Representation for Hardware Generation from High-level Programs},
doi = {10.1109/VLSID.2007.28}
}
@online{convImg,
  author = {Ajitesh Kumar},
  title = {Real-World Applications of Convolutional Neural Networks},
  year = 2021,
  url = {https://vitalflux.com/real-world-applications-of-convolutional-neural-networks/},
  urldate = {2021-11-06}
}

@InProceedings{UNET,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@article{CNNs,
  author       = {Keiron O'Shea and
                  Ryan Nash},
  title        = {An Introduction to Convolutional Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1511.08458},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.08458},
  eprinttype    = {arXiv},
  eprint       = {1511.08458},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{SVMs,

  author={Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},

  journal={IEEE Intelligent Systems and their Applications}, 

  title={Support vector machines}, 

  year={1998},

  volume={13},

  number={4},

  pages={18-28},

  doi={10.1109/5254.708428}}

  @ARTICLE{LeNet,

  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},

  journal={Proceedings of the IEEE},

  title={Gradient-based learning applied to document recognition},

  year={1998},

  volume={86},

  number={11},

  pages={2278-2324},

  doi={10.1109/5.726791}}

  @inproceedings{AlexNet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet Classification with Deep Convolutional Neural Networks},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1097–1105},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}

@INPROCEEDINGS{GoogleNet,

  author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},

  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Going deeper with convolutions}, 

  year={2015},

  volume={},

  number={},

  pages={1-9},

  doi={10.1109/CVPR.2015.7298594}}


 @INPROCEEDINGS{ResNet,

  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},

  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Deep Residual Learning for Image Recognition}, 

  year={2016},

  volume={},

  number={},

  pages={770-778},

  doi={10.1109/CVPR.2016.90}}

@INPROCEEDINGS{YOLO,
author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={You Only Look Once: Unified, Real-Time Object Detection},
year={2016},
volume={},
number={},
pages={779-788},
doi={10.1109/CVPR.2016.91}}
@INPROCEEDINGS{CNN1,
author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Improved Texture Networks: Maximizing Quality and Diversity in Feed-Forward Stylization and Texture Synthesis},
year={2017},
volume={},
number={},
pages={4105-4113},
doi={10.1109/CVPR.2017.437}}
@INPROCEEDINGS{CNN2,
author={Huang, Xun and Belongie, Serge},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization},
year={2017},
volume={},
number={},
pages={1510-1519},
doi={10.1109/ICCV.2017.167}}
@INPROCEEDINGS{CNN3,
author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Image-to-Image Translation with Conditional Adversarial Networks},
year={2017},
volume={},
number={},
pages={5967-5976},
doi={10.1109/CVPR.2017.632}}
@INPROCEEDINGS{CNN4,
author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
year={2017},
volume={},
number={},
pages={2242-2251},
doi={10.1109/ICCV.2017.244}}
@INPROCEEDINGS{CNN5,
author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation},
year={2018},
volume={},
number={},
pages={8789-8797},
doi={10.1109/CVPR.2018.00916}}
@INPROCEEDINGS{CNN6,
author={Shi, Wenzhe and Caballero, Jose and Huszár, Ferenc and Totz, Johannes and Aitken, Andrew P. and Bishop, Rob and Rueckert, Daniel and Wang, Zehan},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network},
year={2016},
volume={},
number={},
pages={1874-1883},
doi={10.1109/CVPR.2016.207}}
@INPROCEEDINGS{CNN7,
author={Kim, Jiwon and Lee, Jung Kwon and Lee, Kyoung Mu},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Accurate Image Super-Resolution Using Very Deep Convolutional Networks},
year={2016},
volume={},
number={},
pages={1646-1654},
doi={10.1109/CVPR.2016.182}}


@inproceedings{TPU,
title	= {In-Datacenter Performance Analysis of a Tensor Processing Unit},
author	= {Norman P. Jouppi and Cliff Young and Nishant Patil and David Patterson and Gaurav Agrawal and Raminder Bajwa and Sarah Bates and Suresh Bhatia and Nan Boden and Al Borchers and Rick Boyle and Pierre-luc Cantin and Clifford Chao and Chris Clark and Jeremy Coriell and Mike Daley and Matt Dau and Jeffrey Dean and Ben Gelb and Tara Vazir Ghaemmaghami and Rajendra Gottipati and William Gulland and Robert Hagmann and C. Richard Ho and Doug Hogberg and John Hu and Robert Hundt and Dan Hurt and Julian Ibarz and Aaron Jaffey and Alek Jaworski and Alexander Kaplan and Harshit Khaitan and Andy Koch and Naveen Kumar and Steve Lacy and James Laudon and James Law and Diemthu Le and Chris Leary and Zhuyuan Liu and Kyle Lucke and Alan Lundin and Gordon MacKean and Adriana Maggiore and Maire Mahony and Kieran Miller and Rahul Nagarajan and Ravi Narayanaswami and Ray Ni and Kathy Nix and Thomas Norrie and Mark Omernick and Narayana Penukonda and Andy Phelps and Jonathan Ross},
year	= {2017},
URL	= {https://arxiv.org/pdf/1704.04760.pdf}
}


